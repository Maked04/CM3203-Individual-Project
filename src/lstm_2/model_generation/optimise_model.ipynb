{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697e54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b15744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Local imports\n",
    "from src.data_processing.lstm_data_preprocessing import reduce_time_bucket_features, FeaturesConfig\n",
    "from src.data_processing.loader import load_time_bucket_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6345463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configs\n",
    "features_config = FeaturesConfig(\n",
    "        relative_time=True,\n",
    "        price_change=True,\n",
    "        trade_size_ratio=True,\n",
    "        liquidity_ratio=True,\n",
    "        wallet_trade_size_deviation=True,\n",
    "        rough_pnl=True,\n",
    "        average_roi=True,\n",
    "        win_rate=True,\n",
    "        average_hold_duration=True\n",
    "    )\n",
    "\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794539b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train - test data\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "time_bucket_folder = \"time_bucket_1\"  # Change based on which time bucket configuration you want to used, their preprocessed in different folders\n",
    "token_time_buckets, time_bucket_config = load_time_bucket_data(time_bucket_folder)\n",
    "\n",
    "token_datasets = []\n",
    "for token_address, data in token_time_buckets.items():\n",
    "    X = data[\"X\"]\n",
    "    y = data[\"y\"]\n",
    "    bucket_times = data[\"bucket_times\"]\n",
    "\n",
    "    # Only get the features listed in features_config\n",
    "    X = reduce_time_bucket_features(X, features_config)\n",
    "\n",
    "    token_datasets.append((X, y, token_address, bucket_times))\n",
    "\n",
    "# Combine all token data\n",
    "all_X = np.vstack([data[0] for data in token_datasets])\n",
    "all_y = np.vstack([data[1].reshape(-1, 1) for data in token_datasets])\n",
    "\n",
    "# Scale features\n",
    "num_samples, time_steps, features = all_X.shape\n",
    "X_reshaped = all_X.reshape(num_samples * time_steps, features)\n",
    "X_scaled = X_scaler.fit_transform(X_reshaped)\n",
    "X_scaled = X_scaled.reshape(num_samples, time_steps, features)\n",
    "\n",
    "# Scale target variable also using StandardScaler to preserve direction\n",
    "y_scaled = y_scaler.fit_transform(all_y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20162865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 31m 37s]\n",
      "val_loss: 4.023556232452393\n",
      "\n",
      "Best val_loss So Far: 3.733747959136963\n",
      "Total elapsed time: 19h 21m 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maked/CM3203-Project/CM3203-Venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 42 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Masking, LSTM, Bidirectional, BatchNormalization, Dropout, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "\n",
    "# Custom loss function\n",
    "def weighted_mse_large_moves(y_true, y_pred):\n",
    "    diff = y_true - y_pred\n",
    "    weight = tf.math.square(y_true)\n",
    "    return tf.reduce_mean(weight * tf.square(diff))\n",
    "\n",
    "# Model building function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Masking(mask_value=0., input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    \n",
    "    model.add(Bidirectional(\n",
    "        LSTM(\n",
    "            units=hp.Int('lstm_units_1', 32, 128, step=16),\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=regularizers.l2(hp.Choice('l2_reg', [1e-5, 1e-4, 1e-3]))\n",
    "        )\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_1', 0.1, 0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Bidirectional(\n",
    "        LSTM(\n",
    "            units=hp.Int('lstm_units_2', 32, 128, step=16),\n",
    "            return_sequences=False,\n",
    "            kernel_regularizer=regularizers.l2(hp.Choice('l2_reg', [1e-5, 1e-4, 1e-3]))\n",
    "        )\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(hp.Float('dropout_2', 0.1, 0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(\n",
    "        hp.Int('dense_units', 16, 64, step=16),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    \n",
    "    model.add(Dense(1))  # Fixed output\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=hp.Choice('learning_rate', [1e-3, 5e-4, 1e-4])\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=weighted_mse_large_moves)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Setup BayesianOptimization tuner\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=30,            # You can adjust: more trials = better search\n",
    "    directory='tuner_results',\n",
    "    project_name='bilstm_bayesian'\n",
    ")\n",
    "\n",
    "# EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    mode='min',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Start search\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,   # fixed\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89210a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_models/lstm_16/model.keras\n",
      "Configuration saved to trained_models/lstm_16/config.json\n",
      "\n",
      "All model artifacts saved to trained_models/lstm_16\n"
     ]
    }
   ],
   "source": [
    "from helper_methods import save_model_with_config\n",
    "\n",
    "save_model_with_config(\n",
    "    model=best_model,\n",
    "    tuner=tuner,\n",
    "    features_config=features_config,\n",
    "    time_bucket_folder=time_bucket_folder,\n",
    "    test_size=test_size,\n",
    "    early_stopping=early_stopping,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CM3203-Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
